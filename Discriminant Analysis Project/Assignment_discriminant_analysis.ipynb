{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DISCRIMINANT ANALYSIS\n",
    "\n",
    "In this coding assignment you are to implement a Minimum Risk Bayes Decision Theoretic classifier and use it to classify the test examples in the provided datasets.  \n",
    "Assume the following:\n",
    "1. All conditional density functions are multivariate Gaussian\n",
    "2. Each class has its own covariance matrix\n",
    "3. Equally likely prior probabilities\n",
    "4. 0-1 loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length   sepal_width   petal_length   petal_width   class\n",
      "0        5.7147        2.6743         3.2696       1.65440       2\n",
      "1        5.1734        3.7374         5.9442       3.00050       3\n",
      "2        7.3776        3.1505         3.3543       0.64839       2\n",
      "3        6.4908        2.3983         3.3917       1.54950       2\n",
      "4        6.8182        3.4016         4.7495       0.57970       3\n",
      "   sepal_length   sepal_width   petal_length   petal_width   class\n",
      "0           4.4           2.9            1.4           0.2       1\n",
      "1           6.7           3.0            5.2           2.3       3\n",
      "2           4.9           3.1            1.5           0.2       1\n",
      "3           5.1           2.5            3.0           1.1       2\n",
      "4           6.1           3.0            4.6           1.4       2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import logm, expm\n",
    "\n",
    "# Load training data - 135 observations, 4 features, 3 classes, \n",
    "df = pd.read_csv(\"iris_corrupted_training_data.csv\")\n",
    "print(df.head())\n",
    "df = df.values\n",
    "tr_data = df\n",
    "\n",
    "# Load validation data - 15 samples\n",
    "df = pd.read_csv(\"iris_validation_data.csv\")\n",
    "print(df.head())\n",
    "df = df.values\n",
    "val_data = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance MLE function\n",
    "def covmle(data, mean):\n",
    "    \"\"\"\n",
    "      data is a matrix size N x 4\n",
    "      mean is a vector size 4 x 1\n",
    "    \"\"\"\n",
    "    X = np.array(data[:,0:4])\n",
    "    m = np.array(mean)\n",
    "    XM = X - m\n",
    "    #print(np.shape(mean))\n",
    "    return np.dot(XM.transpose(), XM) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Compute various components of the disriminant function\n",
    "# \n",
    "# Suggestion: create data matrices for each class\n",
    "# ...\n",
    "\n",
    "#create data matrices for each of the 3 classes\n",
    "class1_arr = []\n",
    "class2_arr = []\n",
    "class3_arr = []\n",
    "\n",
    "\n",
    "for i in range(0, len(tr_data)):\n",
    "    if tr_data[i][4] == 1:\n",
    "        class1_arr.append([])\n",
    "        #add in data 0-3 in row i to class1_arr\n",
    "        for j in range(0, 4):\n",
    "            class1_arr[len(class1_arr)-1].append(tr_data[i][j])\n",
    "            \n",
    "    if tr_data[i][4] == 2:\n",
    "        class2_arr.append([])\n",
    "        #add in data 0-3 in row i to class1_arr\n",
    "        for j in range(0, 4):\n",
    "            class2_arr[len(class2_arr)-1].append(tr_data[i][j])\n",
    "            \n",
    "    if tr_data[i][4] == 3:\n",
    "        class3_arr.append([])\n",
    "        #add in data 0-3 in row i to class1_arr\n",
    "        for j in range(0, 4):\n",
    "            class3_arr[len(class3_arr)-1].append(tr_data[i][j])\n",
    "            \n",
    "\n",
    "# Would normally have to make each length different for each class, but each has 45/label\n",
    "L = len(class1_arr)\n",
    "    \n",
    "\n",
    "# Find the mean_and the covariance_for each class\n",
    "# Use the above covariance function\n",
    "\n",
    "\n",
    "#sum the totals of the columns for each of the 3 arrays to later find the mean\n",
    "arr1_means = [sum(x) for x in zip(*class1_arr)]\n",
    "arr2_means = [sum(x) for x in zip(*class2_arr)]\n",
    "arr3_means = [sum(x) for x in zip(*class3_arr)]\n",
    "\n",
    "#take the total sum of each of the columns and then divide each element by L=45 to get the mean\n",
    "arr1_means = [x / L for x in arr1_means]\n",
    "arr2_means = [x / L for x in arr2_means]\n",
    "arr3_means = [x / L for x in arr3_means]\n",
    "\n",
    "\n",
    "#compute the covarience array using each class array and means\n",
    "arr1_cov = covmle(np.asarray(class1_arr), arr1_means)\n",
    "arr2_cov = covmle(np.asarray(class2_arr), arr2_means)\n",
    "arr3_cov = covmle(np.asarray(class3_arr), arr3_means)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the determinant, the log and the inverse log\n",
    "# ...\n",
    "\n",
    "\n",
    "#compute the determinant of each covarience matrix\n",
    "arr1_d = np.linalg.det(arr1_cov)\n",
    "arr2_d = np.linalg.det(arr2_cov)\n",
    "arr3_d = np.linalg.det(arr3_cov)\n",
    "\n",
    "\n",
    "#compute the log of each class determinant\n",
    "arr1_detlog = np.log(np.linalg.det(arr1_cov))\n",
    "arr2_detlog = np.log(np.linalg.det(arr2_cov))\n",
    "arr3_detlog = np.log(np.linalg.det(arr3_cov))\n",
    "\n",
    "#compute the inv of the cov matrix using numpy function\n",
    "arr1_covinv = np.linalg.inv(arr1_cov)\n",
    "arr2_covinv = np.linalg.inv(arr2_cov)\n",
    "arr3_covinv = np.linalg.inv(arr3_cov)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means for class 1, 2, 3:\n",
      "\n",
      "[4.800817777777779, 3.487995555555555, 1.2692098888888892, 0.3478773333333334]\n",
      "\n",
      "[6.065882222222223, 2.822879777777778, 4.262413333333334, 1.1078519666666666]\n",
      "\n",
      "[6.42966, 2.956569555555556, 5.558746666666666, 1.9247654666666674]\n",
      "\n",
      "\n",
      "Covariance matrix for class 1, 2, 3:\n",
      "[[ 0.72206319 -0.09570774  0.15849484  0.09220771]\n",
      " [-0.09570774  1.02194573  0.08067128  0.05986411]\n",
      " [ 0.15849484  0.08067128  0.73711485  0.07575562]\n",
      " [ 0.09220771  0.05986411  0.07575562  0.502064  ]]\n",
      "\n",
      "[[ 1.00385223  0.15694398  0.28097557 -0.10609686]\n",
      " [ 0.15694398  0.78627333  0.19772005 -0.07156185]\n",
      " [ 0.28097557  0.19772005  0.72402688 -0.04282879]\n",
      " [-0.10609686 -0.07156185 -0.04282879  0.68125752]]\n",
      "\n",
      "[[1.33244449 0.26017373 0.43578404 0.29662547]\n",
      " [0.26017373 1.01624949 0.12567658 0.18028235]\n",
      " [0.43578404 0.12567658 0.68059088 0.22510266]\n",
      " [0.29662547 0.18028235 0.22510266 0.83851244]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print the mean vectors and the covariance matrices\n",
    "\n",
    "print(\"means for class 1, 2, 3:\")\n",
    "print()\n",
    "print(arr1_means)\n",
    "print()\n",
    "print(arr2_means)\n",
    "print()\n",
    "print(arr3_means)\n",
    "print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Covariance matrix for class 1, 2, 3:\")\n",
    "print(arr1_cov)\n",
    "print()\n",
    "print(arr2_cov)\n",
    "print()\n",
    "print(arr3_cov)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy =  0.8667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model accuracy with validation data\n",
    "\n",
    "# For each sample, compute the discriminant function (g1, g2, g3) corresponding to each class\n",
    "# Assume prior = 1/3\n",
    "# The predicted class label is the largest of g1, g2, g3\n",
    "# Count the number of correctly predicted labels\n",
    "\n",
    "correct_class = 0;  # number of correctly predicted label\n",
    "\n",
    "\n",
    "#################\n",
    "#variable names (for class 1. replace 1 with 2/3 for other classes):\n",
    "#\n",
    "#class1_arr = original data in for each class                 size: 45x4\n",
    "#arr1_means = mean vector                                     size: 4x1\n",
    "#arr1_d = determinant of cov matrix                           size: scalar value\n",
    "#arr1_cov = covarience matrix                                 size: 4x4\n",
    "#arr1_detlog = log of the covarience matrix                   size: scalar value\n",
    "#arr1_covinv = inverseof the covarience matrix                size: 4x4\n",
    "#\n",
    "#################\n",
    "\n",
    "d = 4\n",
    "\n",
    "for i in range(0, len(val_data)):\n",
    "    #CLASS 1:\n",
    "    xmean = arr1_means - val_data_nc[i]\n",
    "    #compute the ((-.5) * mean^t * cov * mean) term separately for clarity\n",
    "    meancov = ((-.5) * np.matmul(np.matmul(np.transpose(xmean), arr1_cov), xmean))\n",
    "    g1 = meancov - ((d/2)* np.log(2*np.pi)) - ((.5)*arr1_detlog) + np.log(1/3)\n",
    "    \n",
    "    #CLASS2:\n",
    "    xmean = arr2_means-val_data_nc[i]\n",
    "    #compute the ((-.5) * mean^t * cov * mean) term separately for clarity\n",
    "    meancov = ((-.5) * np.matmul(np.matmul(np.transpose(xmean), arr2_cov), xmean))\n",
    "    g2 = meancov - ((d/2)* np.log(2*np.pi)) - ((.5)*arr2_detlog) + np.log(1/3)\n",
    "    \n",
    "    #CLASS3:\n",
    "    xmean = arr3_means-val_data_nc[i]\n",
    "    #compute the ((-.5) * mean^t * cov * mean) term separately for clarity\n",
    "    meancov = ((-.5) * np.matmul(np.matmul(np.transpose(xmean), arr3_cov), xmean))\n",
    "    g3 = meancov - ((d/2)* np.log(2*np.pi)) - ((.5)*arr3_detlog) + np.log(1/3)\n",
    "    \n",
    "    \n",
    "    gi = max(g1,g2,g3)\n",
    "    if (gi == g1):\n",
    "        gi = 1\n",
    "    elif (gi == g2):\n",
    "        gi = 2\n",
    "    elif (gi == g3):\n",
    "        gi = 3\n",
    "    if (gi == val_data[i][4]):\n",
    "        correct_class += 1\n",
    "    \n",
    "    \n",
    "print('Classification accuracy = ', '{0:.4f}'. format(correct_class/15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
